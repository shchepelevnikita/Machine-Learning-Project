{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alien-premiere",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "motivated-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-emperor",
   "metadata": {},
   "source": [
    "# А.Работа с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-forge",
   "metadata": {},
   "source": [
    "## А.1 Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optimum-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/pokemon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-arcade",
   "metadata": {},
   "source": [
    "## А.2 Краткий обзор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broken-drain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>525</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>625</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>309</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                   Name Type 1  Type 2  Total  HP  Attack  Defense  \\\n",
       "0  1              Bulbasaur  Grass  Poison    318  45      49       49   \n",
       "1  2                Ivysaur  Grass  Poison    405  60      62       63   \n",
       "2  3               Venusaur  Grass  Poison    525  80      82       83   \n",
       "3  3  VenusaurMega Venusaur  Grass  Poison    625  80     100      123   \n",
       "4  4             Charmander   Fire     NaN    309  39      52       43   \n",
       "\n",
       "   Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0       65       65     45           1      False  \n",
       "1       80       80     60           1      False  \n",
       "2      100      100     80           1      False  \n",
       "3      122      120     80           1      False  \n",
       "4       60       50     65           1      False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lined-certification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   #           800 non-null    int64 \n",
      " 1   Name        800 non-null    object\n",
      " 2   Type 1      800 non-null    object\n",
      " 3   Type 2      414 non-null    object\n",
      " 4   Total       800 non-null    int64 \n",
      " 5   HP          800 non-null    int64 \n",
      " 6   Attack      800 non-null    int64 \n",
      " 7   Defense     800 non-null    int64 \n",
      " 8   Sp. Atk     800 non-null    int64 \n",
      " 9   Sp. Def     800 non-null    int64 \n",
      " 10  Speed       800 non-null    int64 \n",
      " 11  Generation  800 non-null    int64 \n",
      " 12  Legendary   800 non-null    bool  \n",
      "dtypes: bool(1), int64(9), object(3)\n",
      "memory usage: 75.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-version",
   "metadata": {},
   "source": [
    "## А.3 Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-satin",
   "metadata": {},
   "source": [
    "### А.3.1 Обработка пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-donor",
   "metadata": {},
   "source": [
    "#### А.3.1.1 k-NN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@kyawsawhtoon/a-guide-to-knn-imputation-95e2dc496e\n",
    "# https://datasciencebeginners.com/2018/11/07/visualization-of-imputed-values-using-vim/ - visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-genius",
   "metadata": {},
   "source": [
    "#### А.3.1.2 Глубокое обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datawig\n",
    "\n",
    "df_train, df_test = datawig.utils.random_split(train)\n",
    "\n",
    "# Инициализируем модель SimpleImputer\n",
    "imputer = datawig.SimpleImputer(\n",
    "    input_columns=['1','2','3','4','5','6','7', 'target'], # из каких столбцов брать информацию для импутации\n",
    "    output_column= '0', # какой столбец восстанавливаем\n",
    "    output_path = 'imputer_model' # куда записывать модель и её метрики\n",
    "    )\n",
    "\n",
    "# Тренируем модель\n",
    "imputer.fit(train_df=df_train, num_epochs=50)\n",
    "\n",
    "# Проводим импутацию и возвращаем восстановленный набор данных\n",
    "imputed = imputer.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-lewis",
   "metadata": {},
   "source": [
    "#### А.3.1.3 Удаление записи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-april",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-suffering",
   "metadata": {},
   "source": [
    "#### А.3.1.4 Удаление признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['feature'], axis=1) or titanic_df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-shadow",
   "metadata": {},
   "source": [
    "#### А.3.1.5 Заполнение самым частым значением"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df['name'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-defendant",
   "metadata": {},
   "source": [
    "#### А.3.1.6 Заполнение самым средним или медианой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(titanic_df.mean()) or df.fillna(titanic_df.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-sydney",
   "metadata": {},
   "source": [
    "### А.3.2 Обработка признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-ribbon",
   "metadata": {},
   "source": [
    "#### А.3.2.2 Обработка категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric\n",
    "def RoseOfWind(data, col):\n",
    "  data[col] = data[col].replace(\"N\"  ,  1)\n",
    "  data[col] = data[col].replace(\"NNE\",  2)\n",
    "  data[col] = data[col].replace(\"NE\" ,  3)\n",
    "  data[col] = data[col].replace(\"ENE\",  4)\n",
    "  data[col] = data[col].replace(\"E\"  ,  5)\n",
    "  data[col] = data[col].replace(\"ESE\",  6)\n",
    "  data[col] = data[col].replace(\"SE\" ,  7)\n",
    "  data[col] = data[col].replace(\"SSE\",  8)\n",
    "  data[col] = data[col].replace(\"S\"  ,  9)\n",
    "  data[col] = data[col].replace(\"SSW\", 10)\n",
    "  data[col] = data[col].replace(\"SW\" , 11)\n",
    "  data[col] = data[col].replace(\"WSW\", 12)\n",
    "  data[col] = data[col].replace(\"W\"  , 13)\n",
    "  data[col] = data[col].replace(\"WNW\", 14)\n",
    "  data[col] = data[col].replace(\"NW\" , 15)\n",
    "  data[col] = data[col].replace(\"NNW\", 16)\n",
    "\n",
    "RoseOfWind(data, 'WindGustDir')\n",
    "RoseOfWind(data, 'WindDir9am')\n",
    "RoseOfWind(data, 'WindDir3pm')\n",
    "\n",
    "#кодируем признаки с помощью метода One-Hot\n",
    "type_1_dummies = pd.get_dummies(pokemon_df['Type 1'])\n",
    "type_2_dummies = pd.get_dummies(pokemon_df['Type 2'])\n",
    "types_df = pd.DataFrame(index = pokemon_df.index)\n",
    "types = list(type_2_dummies.columns.values)\n",
    "for t in types:\n",
    "    types_df[t] = type_1_dummies[t] + type_2_dummies[t]\n",
    "\n",
    "pokemon_df = pd.concat([pokemon_df, types_df], sort = False, axis = 1)\n",
    "\n",
    "#удаляем столбцы Type 1 и Type 2\n",
    "\n",
    "pokemon_df.drop([\"Type 1\",\"Type 2\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-screen",
   "metadata": {},
   "source": [
    "#### А.3.2.2 Обработка порядковых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same lil nigga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-bunch",
   "metadata": {},
   "source": [
    "#### А.3.2.3 Обработка бинарных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df.Legendary.replace({True:1,False:0}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-champagne",
   "metadata": {},
   "source": [
    "#### А.3.2.4 Обработка вещественных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.iloc[:,0:7])\n",
    "scaled_df = pd.DataFrame(np.array(scaler.transform(df.iloc[:,0:7])), columns = [\"Total\",\"HP\",\"Attack\",\"Defense\",\"Sp_Atk\",\"Sp_Def\",\"Speed\"], index = df.index)\n",
    "\n",
    "\n",
    "df = pd.concat([scaled_df, df.iloc[:,7:]], axis = \"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-yugoslavia",
   "metadata": {},
   "source": [
    "### А.3.3 Обработка выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify outliers in the training dataset\n",
    "iso = IsolationForest(contamination=0.1)\n",
    "yhat = iso.fit_predict(X_train)\n",
    "\n",
    "# select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "\n",
    "# evaluate model performance with outliers removed using isolation forest\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# load the dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "df = read_csv(url, header=None)\n",
    "# retrieve the array\n",
    "data = df.values\n",
    "# split into input and output elements\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize the shape of the training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "# identify outliers in the training dataset\n",
    "iso = IsolationForest(contamination=0.1)\n",
    "yhat = iso.fit_predict(X_train)\n",
    "# select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "# summarize the shape of the updated training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "# fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f' % mae)\n",
    "\n",
    "#https://towardsdatascience.com/anomaly-detection-with-isolation-forest-visualization-23cd75c281e2 - visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-reason",
   "metadata": {},
   "source": [
    "### А.3.4 Учет корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(dataframe.corr())\n",
    "plt.show()\n",
    "\n",
    "# heat map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-maldives",
   "metadata": {},
   "source": [
    "## А.4 Визуализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-dragon",
   "metadata": {},
   "source": [
    "### А.4.1 Heat map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-national",
   "metadata": {},
   "source": [
    "### А.4.2 Pair plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-legislature",
   "metadata": {},
   "source": [
    "### А.4.3 Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-integral",
   "metadata": {},
   "source": [
    "### А.4.4 Pie chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-buffer",
   "metadata": {},
   "source": [
    "### А.4.5 Graphic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-outside",
   "metadata": {},
   "source": [
    "# B.Работа с моделями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-pierce",
   "metadata": {},
   "source": [
    "## Отбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "array = data.values\n",
    "X = array[:,0:24]\n",
    "Y = array[:,24]\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)\n",
    "\n",
    "id = []\n",
    "for col in data.columns:\n",
    "    id.append(col)\n",
    "id.pop(24)\n",
    "feat = model.feature_importances_.tolist()\n",
    "ff = pd.DataFrame()\n",
    "ff['Признак'] = id\n",
    "ff['Важность признака'] = feat\n",
    "ff.sort_values(by=['Важность признака'], ascending = False)\n",
    "\n",
    "idNum = []\n",
    "corrArr = []\n",
    "for i in range(24):\n",
    "    idNum.append(i)\n",
    "for col in data.columns:\n",
    "    corrArr.append(np.corrcoef(data[col].values, data['RainTomorrow'].values)[0][1])\n",
    "corrArr.pop(24)\n",
    "\n",
    "fig, ax = plt.subplots(tight_layout=True)\n",
    "hist = ax.hist2d(idNum, corrArr)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.hist(corrArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-russell",
   "metadata": {},
   "source": [
    "## Разбиение выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим датафреймы X и y\n",
    "y = pokemon_df.Legendary\n",
    "pokemon_df = pokemon_df.drop(['Legendary'], axis=1)\n",
    "X = pokemon_df\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#разбиваем всю выборку на обучающую и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-protest",
   "metadata": {},
   "source": [
    "## Модель \"название модели\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-quantity",
   "metadata": {},
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-customer",
   "metadata": {},
   "source": [
    "### Обучение модели без гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-fraction",
   "metadata": {},
   "source": [
    "### Обучение модели с гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-italic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,50,250,500],\n",
    "    \"max_depth\":[1,3,5,7,9],\n",
    "    \"learning_rate\":[0.01,0.1,1,10,100]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator = clf, param_grid = parameters, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-riding",
   "metadata": {},
   "source": [
    "### Оценка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-duration",
   "metadata": {},
   "source": [
    "# C.Заключительная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-space",
   "metadata": {},
   "source": [
    "## Сериализация моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.dumps(Bagging)\n",
    "Bagging_byte = pickle.loads(model)\n",
    "with open('Bagging.pkl', 'wb') as output:\n",
    "       pickle.dump(Bagging, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.dumps(GrBosstClass)\n",
    "GrBosstClass_byte = pickle.loads(model)\n",
    "with open('GrBosstClass.pkl', 'wb') as output:\n",
    "       pickle.dump(GrBosstClass, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-grave",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-floor",
   "metadata": {},
   "source": [
    "## Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def main():\n",
    "  GrBosstClass = load_GRB()\n",
    "  Bagging = load_Bagging()\n",
    "  data = loadSet()\n",
    "  defaulData = loadDefaultSet()\n",
    "  currentModelSelected = 0\n",
    "  vl15H = 0\n",
    "  speedWind = 0\n",
    "  cloydy3H = 0\n",
    "  vl9H = 0\n",
    "  rainToday = 1\n",
    "  sun = 0\n",
    "  tempAir15H = 0\n",
    "  dav15H = 0\n",
    "  minTemp = 0\n",
    "  maxTemp = 0\n",
    "  \n",
    "  st.title(\"Модуль С\")\n",
    "  st.markdown(\"<style> .big-font {font-size:30px !important; }</style>\", unsafe_allow_html=True)\n",
    "  st.sidebar.markdown('<p class=\"big-font\"> <b>Модели</b> </p>', unsafe_allow_html=True)\n",
    "  modelSelect = st.sidebar.radio(\"Выберите модель машинного обучения\", [\"Градиентный бустинг\", \"Бэггиннг\"])\n",
    "\n",
    "  st.sidebar.markdown('<p class=\"big-font\"> <b>Дата сеты</b> </p>', unsafe_allow_html=True)\n",
    "  dataSetSelect = st.sidebar.radio(\"Выберите дата сет\", [\"Исходный\", \"После препроцесса\"])\n",
    "\n",
    "  if dataSetSelect == \"После препроцесса\":\n",
    "    '''В датасете после препроцесса остались только самые важные десять полей. Также перекодированы столбцы: локация, направление ветра и был ли сегодня дождь.'''\n",
    "    st.write(data.head(10))\n",
    "\n",
    "  if dataSetSelect == \"Исходный\":\n",
    "    ''' Исходный датасет имеет полный список полей. Также в нём не заполнены пустые значения и ни один признак не перекодирован.'''\n",
    "    st.write(defaulData.head(10))\n",
    "      \n",
    "\n",
    "  if modelSelect == \"Градиентный бустинг\":\n",
    "    currentModelSelected = GrBosstClass\n",
    "    \"Предсказание градиентного бустинга\"\n",
    "    \"Градиентный бустинг предсказывает с точностью в 85%\"\n",
    "\n",
    "\n",
    "  if modelSelect == \"Бэггиннг\":\n",
    "    currentModelSelected = Bagging\n",
    "    \"Предсказание бэггиннга\"\n",
    "    \"Бэггинг предсказывает с точностью в 84%\"\n",
    "  \"Для предсказания дождя на завтрашний день исопльзуются основные 10 параметров.\"\n",
    "  \"\"  \n",
    "  inpType = st.radio(\"Как будете вводить данные?\", ['Строкой', \"Буду заполнять каждое поле отдельно!\"])\n",
    "  if inpType == \"Буду заполнять каждое поле отдельно!\":\n",
    "    vl15H = st.number_input(\"Влажность воздуха в 15:00\")\n",
    "    speedWind = st.number_input(\"Скорость порыва ветра\")\n",
    "    cloydy3H = st.number_input(\"Облачность в 15:00 (от 0 до 9)\")\n",
    "    vl9H = st.number_input(\"Влажность в 9 утра\")\n",
    "    rainTodayStr = st.radio(\"Был ли сегодня дождь?\", [\"Да\" , \"Нет\"])\n",
    "    rainToday = 1\n",
    "    if rainTodayStr ==\"Да\":\n",
    "      rainToday = 1\n",
    "    else:\n",
    "      rainToday = 0\n",
    "    sun = st.number_input(\"Солнечный свет (от 0 до 13,9)\")\n",
    "    tempAir15H = st.number_input(\"Температура воздуха в 15:00\")\n",
    "    dav15H = st.number_input(\"Давление в 15:00\")\n",
    "    minTemp = st.number_input(\"Минимальная температура воздуха\")\n",
    "    maxTemp = st.number_input(\"Максимальная температура воздуха\")\n",
    "  if inpType == \"Строкой\":\n",
    "    a = st.text_input('Ввести данные строкой:', help= \"Ввдетие числа через запятую. Без точек и запятых в конце строки!\")\n",
    "    if a:\n",
    "      a = a.split(',')\n",
    "      a = [float(i) for i in a]\n",
    "      polya = a\n",
    "  else:\n",
    "    polya = int(currentModelSelected.predict([[vl15H,speedWind,cloydy3H,vl9H,rainToday,sun,tempAir15H,dav15H,minTemp,maxTemp]]))\n",
    "  \"Введенные данные: \" + str(vl15H) + \", \" + str(speedWind) + \", \" + str(cloydy3H) + \", \" + str(vl9H) + \", \" +str(rainToday) + \", \" + str(sun) + \", \" + str(tempAir15H) + \", \" + str(dav15H) + \", \" + str(minTemp) + \", \" + str(maxTemp) + \".\"\n",
    "  if st.button(\"Рассчитать прогноз\", key=None, help=\"Предсказать будет ли дождь завтра при помощи метода \" + modelSelect):\n",
    "    res = polya \n",
    "    if res == 0:\n",
    "      st.markdown(\"<p style=\\\"font-size:30px\\\">Скорее всего завтра не будет дождя &#128516;</p>\", unsafe_allow_html=True)\n",
    "    else:\n",
    "      st.markdown(\"<p style=\\\"font-size:30px\\\">Скорее всего завтра будет дождь... &#128532;</p>\", unsafe_allow_html=True)\n",
    "  \n",
    "@st.cache\n",
    "def loadSet():\n",
    "  df = pd.read_csv(\"data/watherPreProcces.csv\")\n",
    "  return df\n",
    "\n",
    "### models\n",
    "\n",
    "@st.cache\n",
    "def load_GRB():\n",
    "  with open('models/GrBosstClass.pkl', 'rb') as pkl_file:\n",
    "    grb = pickle.load(pkl_file)\n",
    "  return grb\n",
    "\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def load_Bagging():\n",
    "  with open('models/Bagging.pkl', 'rb') as pkl_file:\n",
    "    Bagging = pickle.load(pkl_file)\n",
    "  return Bagging\n",
    "\n",
    "@st.cache\n",
    "def loadDefaultSet():\n",
    "  df = pd.read_csv(\"data/weather.csv\")\n",
    "  return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
